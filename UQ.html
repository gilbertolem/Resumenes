<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
<meta name="generator" content="http://www.nongnu.org/elyxer/"/>
<meta name="create-date" content="2018-06-04"/>
<link rel="stylesheet" href="http://elyxer.nongnu.org/lyx.css" type="text/css" media="all"/>
<title>Converted document</title>
</head>
<body>
<div id="globalWrapper">
<h1 class="title">
<b>Uncertainty Quantification</b>
</h1>
<h2 class="author">
Personal summary by Gilberto Lem
</h2>
<h2 class="Date">
Summer 2018
</h2>
<div class="fulltoc">
<div class="tocheader">
Table of Contents
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Section-1">Section 1:â€ƒIntroduction</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-1.1">Subsection 1.1:â€ƒUncertainty Quantification</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-1.2">Subsection 1.2:â€ƒBasics of Probability Theory and Statistics</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-1.2.1">Subsubsection 1.2.1:â€ƒUnivariate Concepts</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-1.2.2">Subsubsection 1.2.2:â€ƒMultivariate Concepts</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-1.2.3">Subsubsection 1.2.3:â€ƒBiased vs. unbiased estimators</a>
</div>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-2">Section 2:â€ƒSampling Methods</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-2.1">Subsection 2.1:â€ƒMonte Carlo</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-2.2">Subsection 2.2:â€ƒVariance-Reduction Techniques</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsubsection-2.2.1">Subsubsection 2.2.1:â€ƒAntithetic Sampling</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-2.2.2">Subsubsection 2.2.2:â€ƒStratified Sampling</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-2.2.3">Subsubsection 2.2.3:â€ƒControl Variates</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsubsection-2.2.4">Subsubsection 2.2.4:â€ƒImportance Sampling</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-2.3">Subsection 2.3:â€ƒQuasi Monte-Carlo</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-3">Section 3:â€ƒBasic Interpolation and Quadrature</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection-3.1">Subsection 3.1:â€ƒInterpolation</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-3.2">Subsection 3.2:â€ƒQuadrature</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-4">Section 4:â€ƒPolynomial Chaos</a>
</div>
<div class="tocindent">
<div class="toc">
<a class="Link" href="#toc-Subsection--1">Subsection:â€ƒChoosing the type of polynomials</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection--2">Subsection:â€ƒComputing the coefficients</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection--3">Subsection:â€ƒChoosing maximum order of polynomials and quadrature</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection--4">Subsection:â€ƒStatistical properties of the approximation</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Subsection-4.1">Subsection 4.1:â€ƒMultivariate Polynomial Chaos Expansion</a>
</div>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-5">Section 5:â€ƒSparse Grids</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-6">Section 6:â€ƒSensitivity Analysis</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-7">Section 7:â€ƒRandom Fields</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-8">Section 8:â€ƒSoftware</a>
</div>
<div class="toc">
<a class="Link" href="#toc-Section-9">Section 9:â€ƒBayesian Inverse Problems</a>
</div>
</div>

</div>
<div class="Indented">
<p><br/>
</p>

</div>
<h1 class="Section">
<a class="toc" name="toc-Section-1">1</a>â€ƒIntroduction
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-1.1">1.1</a>â€ƒUncertainty Quantification
</h2>
<div class="Unindented">
Uncertainty Quantification determines how likely certain outcomes are if some aspects of the system are not exactly known.
</div>
<div class="Indented">
The number of uncertain parameters is called <b>stochastic dimensionality</b>.
</div>
<div class="Indented">
UQ in general is slow, because one needs to run the model several times to get good results. To speed up the process there are three options:
</div>
<ul>
<li>
Make the deterministic model faster
</li>
<li>
Use surrogate model instead of expensive high-fidelity model (tradeoff for accuracy)
</li>
<li>
Use clever UQ method with low amount of evaluation points (maybe tradeoff for accuracy)
</li>

</ul>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-1.2">1.2</a>â€ƒBasics of Probability Theory and Statistics
</h2>
<div class="Unindented">
A <b>probability space</b> is a triplet <span class="formula">(Î©,â€…â„±,â€…<span class="scriptfont">P</span>),â€…</span>where:
</div>
<ul>
<li>
<span class="formula">Î©</span> is the sample space, the set of all possible single outcomes
</li>
<li>
<span class="formula">â„±</span> (<span class="formula"><i>Ïƒ</i></span>-algebra) is the combinatorial of all the elements of <span class="formula">Î©</span>
</li>
<li>
<span class="formula"><span class="scriptfont">P</span></span> is the probability measure, <span class="formula">â„±â€…â†’â€…[0,â€…1]</span>
</li>

</ul>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-1.2.1">1.2.1</a>â€ƒUnivariate Concepts
</h3>
<div class="Unindented">
A <b>random variable</b> is a function <span class="formula"><i>X</i></span> which maps <span class="formula">Î©â€…â†’â€…â„</span>. It represents an outcome of a random phenomenon as a number.
</div>
<div class="Indented">
We can represent the probability of obtaining <span class="formula"><i>X</i>â€…=â€…<i>x</i></span>, being <span class="formula"><i>x</i></span> a real number, as <span class="formula"><i>f</i><sub><i>X</i></sub>(<i>x</i>)</span> . If <span class="formula"><i>X</i></span> is continuous, this function is called the <b>probability density function (PDF)</b>, if <span class="formula"><i>X</i></span> is discrete, is called the <b>probability mass function (PMF).</b>
</div>
<div class="Indented">
The value of <span class="formula"><i>f</i><sub><i>X</i></sub></span> has to be always greater or equal than zero, and its accumulate value over all its doimain has to be 1.
</div>
<div class="Indented">
Every random variable has an associated <b>Cumulative Distribution Function (CDF)</b>, represented by <span class="formula"><i>F</i><sub><i>X</i></sub>(<i>x</i>).</span> It represents the probability that the random variable <span class="formula"><i>X</i></span> has a value less or equal than a specified <span class="formula"><i>x</i></span>, i.e. <span class="formula"><i>F</i><sub><i>X</i></sub>(<i>x</i>)â€…=â€…<span class="scriptfont">P</span>{<i>X</i>â€…â‰¤â€…<i>x</i>}.</span> This can be represented as an integral:
</div>
<div class="Indented">
<div class="formula">
<i>F</i><sub><i>X</i></sub>(<i>x</i>)â€…=â€…<span class="limits"><sup class="limit"><i>x</i></sup><span class="limit">âŒ </span><span class="limit">âŒ¡</span><sub class="limit">â€…âˆ’â€…âˆ</sub></span><i>f</i><sub><i>X</i></sub>(<i>s</i>)<i>ds</i>
</div>

</div>
<div class="Indented">
The <b>expectation</b> of a continuous random variable <span class="formula"><i>X</i></span> is defined as:
</div>
<div class="Indented">
<div class="formula">
<i>Î¼</i>â‰”ğ”¼[<i>X</i>]â€…=â€…<span class="limits"><span class="limit">âŒ </span><span class="limit">âŒ¡</span></span><i>xf</i><sub><i>X</i></sub>(<i>x</i>)<i>dx</i>
</div>

</div>
<div class="Indented">
The <b>variance </b>of<b> <span class="formula"><i>X</i></span> </b>is the expected value of the square of the variation of <span class="formula"><i>X</i></span> with respect to its mean:
</div>
<div class="Indented">
<div class="formula">
<i>Ïƒ</i><sup>2</sup>â‰”<span class="mathrm">â€…Var(</span><i>X</i>)â€…=â€…<span class="limits"><span class="limit">âŒ </span><span class="limit">âŒ¡</span></span>(<i>x</i>â€…âˆ’â€…ğ”¼[<i>X</i>])<sup>2</sup><i>f</i><sub><i>X</i></sub>(<i>x</i>)<i>dx</i>â€…=â€…ğ”¼[<i>X</i><sup>2</sup>]â€…âˆ’â€…ğ”¼[<i>X</i>]<sup>2</sup>
</div>

</div>
<div class="Indented">
If <span class="formula"><i>X</i></span> is discrete, the <b>sample mean </b>and <b>sample variance</b> are defined:
</div>
<div class="Indented">
<div class="formula">
<span class="bar"><i>X</i></span>â€…=â€…<span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator"><i>n</i></span><span class="ignored">)</span></span><span class="limits"><sup class="limit">â€…</sup><span class="limit">â²</span><span class="limit">â³</span><sub class="limit"><i>i</i></sub></span><i>X</i><sub><i>i</i></sub>,â€…            <i>S</i><sup>2</sup>â€…=â€…<span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator"><i>n</i>â€…âˆ’â€…1</span><span class="ignored">)</span></span><span class="limits"><sup class="limit">â€…</sup><span class="limit">â²</span><span class="limit">â³</span><sub class="limit"><i>i</i></sub></span>(<i>X</i><sub><i>i</i></sub>â€…âˆ’â€…<span class="bar"><i>X</i></span>)<sup>2</sup>
</div>

</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-1.2.2">1.2.2</a>â€ƒMultivariate Concepts
</h3>
<div class="Unindented">
<span class="formula"><i>X</i></span> can be generalized to a n-dimensional random vector <span class="formula"><b>X</b>,â€…</span> which maps <span class="formula">Î©â€…â†’â€…â„<sup><i>n</i></sup>.</span> <span class="formula"><b>X</b></span> consists of <span class="formula"><i>n</i></span> random variables.
</div>
<div class="Indented">
The <b>covariance</b> of two random variables <span class="formula"><i>X</i></span> and <span class="formula"><i>Y</i></span> is
</div>
<div class="Indented">
<div class="formula">
<i>cov</i>(<i>X</i>,â€…<i>Y</i>)â€…=â€…ğ”¼[ (<i>X</i>â€…âˆ’â€…ğ”¼[<i>X</i>])(<i>Y</i>â€…âˆ’â€…ğ”¼[<i>Y</i>]) ]â€…=â€…ğ”¼[<i>XY</i>]â€…âˆ’â€…ğ”¼[<i>X</i>]ğ”¼[<i>Y</i>]
</div>

</div>
<div class="Indented">
Covariance is high when <span class="formula"><i>X</i></span> and <span class="formula"><i>Y</i></span> are &ldquo;similar&rdquo;.
</div>
<div class="Indented">
If you normalize this covariance you get the <b>Pearson correlation coefficient:</b>
</div>
<div class="Indented">
<div class="formula">
<i>Ï</i><sub><i>XY</i></sub>â€…=â€…<span class="fraction"><span class="ignored">(</span><span class="numerator"><i>cov</i>(<i>X</i>,â€…<i>Y</i>)</span><span class="ignored">)/(</span><span class="denominator"><span class="mathrm">Var(</span><i>X</i>)<span class="mathrm">Var(</span><i>Y</i>)</span><span class="ignored">)</span></span>
</div>

</div>
<div class="Indented">
which have values <span class="formula">[â€…âˆ’â€…1,â€…1]</span>.
</div>
<div class="Paragraph">
<a class="toc" name="toc-Paragraph-1"></a>Independence
</div>
<div class="Unindented">
Let <span class="formula"><i>A</i></span> and <span class="formula"><i>B</i></span> denote two events. If the probability for <span class="formula"><i>A</i></span> to occur is the same if <span class="formula"><i>B</i></span> happens or if <span class="formula"><i>B</i></span> does not happen, <span class="formula"><i>A</i></span> and <span class="formula"><i>B</i></span> are <b>independent. </b>If additionally, both events have the same distribution of probability, they are <b>independent and identically distributed (iid) </b>random variables.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-1.2.3">1.2.3</a>â€ƒBiased vs. unbiased estimators
</h3>
<div class="Unindented">
An <b>estimator</b> is a procedure to construct estimates for a quantity <span class="formula"><i>q</i></span> based on random samples. An <b>estimate</b> is a realization of the estimator. Example estimators are the mean and the variance.
</div>
<div class="Indented">
An estimator is called <b>biased</b> if its expected value is not the same as the parameter to be estimated.
</div>
<div class="Indented">
Correspondingly, an <b>unbiased</b> estimator is when the expected value of the estimator of a sample is equal to the real value of the parameter we are estimating. 
</div>
<div class="Indented">
For an unbiased mean, if we take the mean of a sample, we would expect the same as the mean of the population.
</div>
<div class="Indented">
In the following equations, <span class="formula"><span class="bar"><i>X</i></span></span> and <span class="formula"><i>S</i><sup>2</sup></span> represent unbiased estimators:
</div>
<div class="Indented">
<div class="formula">
ğ”¼[<span class="bar"><i>X</i></span>]â€…=â€…<i>Î¼</i>,â€…          ğ”¼[<i>S</i><sup>2</sup>]â€…=â€…<i>Ïƒ</i><sup>2</sup>
</div>

</div>
<div class="Indented">
If we take the following definitions of <span class="formula"><span class="bar"><i>X</i></span></span> and <span class="formula"><i>S</i><sup>2</sup>:</span>
</div>
<div class="Indented">
<div class="formula">
<span class="bar"><i>X</i></span>â€…=â€…<span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator"><i>n</i></span><span class="ignored">)</span></span><span class="limits"><sup class="limit">â€…</sup><span class="limit">â²</span><span class="limit">â³</span><sub class="limit"><i>i</i></sub></span><i>X</i><sub><i>i</i></sub>          <i>S</i><sup>2</sup>â€…=â€…<span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator"><i>n</i></span><span class="ignored">)</span></span><span class="limits"><sup class="limit">â€…</sup><span class="limit">â²</span><span class="limit">â³</span><sub class="limit"><i>i</i></sub></span><span class="symbol">(</span><i>X</i><sub><i>i</i></sub>â€…âˆ’â€…<span class="bar"><i>X</i></span><span class="symbol">)</span><sup>2</sup>
</div>

</div>
<div class="Indented">
<span class="formula"><span class="bar"><i>X</i></span></span> is unbiased but <span class="formula"><i>S</i><sup>2</sup></span> is biased. To correct for this, we multiply our definition of sample variance by <span class="formula"><i>n</i>â€…â„â€…(<i>n</i>â€…âˆ’â€…1)</span> to end up with:
</div>
<div class="Indented">
<div class="formula">
<i>S</i><sup>2</sup>â€…=â€…<span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator"><i>n</i>â€…âˆ’â€…1</span><span class="ignored">)</span></span><span class="limits"><sup class="limit">â€…</sup><span class="limit">â²</span><span class="limit">â³</span><sub class="limit"><i>i</i></sub></span><span class="symbol">(</span><i>X</i><sub><i>i</i></sub>â€…âˆ’â€…<span class="bar"><i>X</i></span><span class="symbol">)</span><sup>2</sup>
</div>

</div>
<div class="Indented">
Note that numpyâ€™s var function computes the biased version of the variance. When we use that funcion we have to correct it.
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-2">2</a>â€ƒSampling Methods
</h1>
<div class="Unindented">
Sampling methods consist in select a subset of &ldquo;individuals&rdquo; from a statistical &ldquo;population&rdquo;, to estimate characteristics of the whole population.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-2.1">2.1</a>â€ƒMonte Carlo
</h2>
<div class="Unindented">
<b>Monte Carlo Sampling</b> consists in generating samples with a pseudo-random number generator from a given probability distribution. After that compute deterministic computation with these samples and aggregate the results. 
</div>
<div class="Indented">
One application of Monte Carlo Sampling is Monte Carlo Integration. It computes the value of an integral of a function over a domain via sampling of the function. The error of the approximation is given by the <b>Root Mean Squared Error:</b>
</div>
<div class="Indented">
<div class="formula">
<i>RMSE</i>â‰”<span class="sqrt"><span class="radical">âˆš</span><span class="ignored">(</span><span class="root">ğ”¼<span class="symbol">[</span>(<i>I</i>â€…âˆ’â€…<i>IÌ‚</i><sub><i>f</i></sub>)<sup>2</sup><span class="symbol">]</span></span><span class="ignored">)</span></span>
</div>

</div>
<div class="Indented">
Or with the equivalent expression:
</div>
<div class="Indented">
<div class="formula">
<i>RMSE</i>â€…â‰ˆâ€…<span class="fraction"><span class="ignored">(</span><span class="numerator"><i>ÏƒÌ‚</i><sub><i>f</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="sqrt"><span class="radical">âˆš</span><span class="ignored">(</span><span class="root"><i>N</i></span><span class="ignored">)</span></span></span><span class="ignored">)</span></span>
</div>

</div>
<div class="Indented">
with <div class="formula">
<i>ÏƒÌ‚</i><sub><i>f</i></sub>â€…=â€…<span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator"><i>N</i>â€…âˆ’â€…1</span><span class="ignored">)</span></span><span class="limits"><sup class="limit">â€…</sup><span class="limit">â²</span><span class="limit">â³</span><sub class="limit"><i>i</i></sub></span><span class="symbol">(</span><i>f</i>(<i>U</i><sub><i>i</i></sub>)â€…âˆ’â€…<i>IÌ‚</i><sub><i>f</i></sub><span class="symbol">)</span><sup>2</sup>
</div>

</div>
<div class="Indented">
Monte Carlo Sampling is easy, robust and embarassingly parallel, but its convergence rate is <span class="formula"><span class="scriptfont">O</span>(<span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator"><span class="sqrt"><span class="radical">âˆš</span><span class="ignored">(</span><span class="root"><i>N</i></span><span class="ignored">)</span></span></span><span class="ignored">)</span></span>),â€…</span> although independent of the input dimension, is very slow.
</div>
<div class="Indented">
So, how can we reduced the RMSE given by Monte Carlo? We could make our simulations faster, also we could increase N (which is not desirable because it would require more deterministic simulations), decrease <span class="formula"><i>ÏƒÌ‚</i><sub><i>f</i></sub></span> (variance-reduction techniques) or improve the random number generation (quasi-montecarlo).
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-2.2">2.2</a>â€ƒVariance-Reduction Techniques
</h2>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-2.2.1">2.2.1</a>â€ƒAntithetic Sampling
</h3>
<div class="Unindented">
We can use a different sampling (choosing of <span class="formula"><i>X</i></span> values) to reduce the variance. This type of sampling assumes that a continuous PDF <span class="formula"><i>f</i><sub><i>X</i></sub>(<i>x</i>)</span> is symmetric around <span class="formula"><i>c</i></span>. This implies that the symmetric counterpart of <span class="formula"><i>x</i></span> is <span class="formula"><i>xÌƒ</i>â€…=â€…2<i>c</i>â€…âˆ’â€…<i>x</i>,â€…</span>and that <span class="formula"><i>f</i><sub><i>X</i></sub>(<i>x</i>)â€…=â€…<i>f</i><sub><i>X</i></sub>(<i>xÌƒ</i>).</span>
</div>
<div class="Indented">
Thus, we can sample <span class="formula"><i>n</i>â€…â„â€…2</span> times from <span class="formula"><i>f</i><sub><i>X</i></sub>(<i>x</i>)</span> and the remaining <span class="formula"><i>n</i>â€…â„â€…2</span> samples are obtained via reflection.
</div>
<div class="Indented">
For example for an uniform distribution in <span class="formula">[0,â€…1],â€…</span>we would get <span class="formula"><i>n</i>â€…â„â€…2</span> values for <span class="formula"><i>X</i>,â€…</span> and the rest of the <span class="formula"><i>n</i>â€…â„â€…2</span> values would be obtained with the relation <span class="formula"><i>UÌƒ</i>â€…=â€…1â€…âˆ’â€…<i>U</i></span>.
</div>
<div class="Indented">
Taking into account the symmetry of the function helps reducing the variance of the sampling.
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-2.2.2">2.2.2</a>â€ƒStratified Sampling
</h3>
<div class="Unindented">
This type of sampling divides the interval of sampling to prevent clustering in a particular region of the interval. Suppose our interval is <span class="formula">[<i>x</i><sub><i>i</i></sub>,â€…<i>x</i><sub><i>f</i></sub>].</span> We would choose a <span class="formula"><i>Î»</i>â€…âˆˆâ€…<span class="symbol">(</span>0,â€…1<span class="symbol">)</span></span> and make two intervals. We take <span class="formula"><i>Î»</i><i>n</i></span> samples in <span class="formula">[<i>x</i><sub><i>i</i></sub>,â€…<i>Î»</i>(<i>x</i><sub><i>f</i></sub>â€…âˆ’â€…<i>x</i><sub><i>i</i></sub>)]</span> and <span class="formula">(1â€…âˆ’â€…<i>Î»</i>)<i>n</i></span> samples in <span class="formula">[<i>Î»</i>(<i>x</i><sub><i>f</i></sub>â€…âˆ’â€…<i>x</i><sub><i>i</i></sub>),â€…<i>x</i><sub><i>f</i></sub>].</span>
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-2.2.3">2.2.3</a>â€ƒControl Variates
</h3>
<div class="Unindented">
This does not reduce the variance through sampling, but through an auxilary function. We take as an illustratory example the estimation of the integral of <span class="formula"><i>f</i>(<i>x</i>)</span> over a domain. Here we introduce a control function <span class="formula"><i>Ï†</i>,â€…</span> which can be easily integrated in that domain.
</div>
<div class="Indented">
<div class="formula">
<i>I</i>â€…=â€…<span class="limits"><span class="limit">âŒ </span><span class="limit">âŒ¡</span></span><i>f</i>(<i>x</i>)<i>dx</i>â€…=â€…<span class="limits"><span class="limit">âŒ </span><span class="limit">âŒ¡</span></span>(<i>f</i>â€…âˆ’â€…<i>Ï†</i>)<i>dx</i>â€…+â€…<span class="limits"><span class="limit">âŒ </span><span class="limit">âŒ¡</span></span><i>Ï†</i><i>dx</i>
</div>

</div>
<div class="Indented">
We know the exact integral for <span class="formula"><i>Ï†</i>,â€…</span> so we would only need to sample the difference. If we look at the variance of the difference:
</div>
<div class="Indented">
<div class="formula">
<span class="mathrm">Var(</span><i>f</i>â€…âˆ’â€…<i>Ï†</i>)â€…=â€…<span class="mathrm">Var(</span><i>f</i>)â€…+â€…<span class="mathrm">Var(</span><i>Ï†</i>)â€…âˆ’â€…2<i>cov</i>(<i>f</i>,â€…<i>Ï†</i>)
</div>

</div>
<div class="Indented">
we note that if <span class="formula"><i>cov</i>(<i>f</i>,â€…<i>Ï†</i>)</span> is high, then <span class="formula"><span class="mathrm">Var(</span><i>f</i>â€…âˆ’â€…<i>Ï†</i>)â€…&lt;â€…<span class="mathrm">Var(</span><i>f</i>),â€…</span> and we would have reduced the variance. So we only need to find a &ldquo;similar function&rdquo; to <span class="formula"><i>f</i>.</span> 
</div>
<h3 class="Subsubsection">
<a class="toc" name="toc-Subsubsection-2.2.4">2.2.4</a>â€ƒImportance Sampling
</h3>
<div class="Unindented">
In a similar way to control variates, if we in Monte Carlo instead of sampling from the uniform distribution, sample from another function <span class="formula"><i>g</i><sub><i>X</i></sub>,â€…</span> and <span class="formula"><i>f</i></span> and <span class="formula"><i>g</i><sub><i>X</i></sub></span> have similar shapes, then variance is reduced.
</div>
<div class="Indented">
<div class="formula">
<i>I</i>â€…=â€…<span class="limits"><span class="limit">âŒ </span><span class="limit">âŒ¡</span></span><i>f</i>(<i>x</i>)<i>dx</i>â€…=â€…<span class="limits"><span class="limit">âŒ </span><span class="limit">âŒ¡</span></span><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>f</i>(<i>x</i>)</span><span class="ignored">)/(</span><span class="denominator"><i>g</i><sub><i>X</i></sub>(<i>x</i>)</span><span class="ignored">)</span></span><i>g</i><sub><i>X</i></sub>(<i>x</i>)<i>dx</i>
</div>

</div>
<div class="Indented">
In this case, the sampling would be done according to the <span class="formula"><i>g</i><sub><i>X</i></sub>,â€…</span>and the function to evaluate would be <span class="formula"><i>f</i>(<i>x</i>)â€…â„â€…<i>g</i><sub><i>x</i></sub>(<i>x</i>)</span>.
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-2.3">2.3</a>â€ƒQuasi Monte-Carlo
</h2>
<div class="Unindented">
Consists in alternative sampling techniques. Instead of using pseudo-random samples as in standard Monte-Carlo, which would result in a nonuniform sampling, we use deterministic samples. Examples are Fibonacci generators, latin hypercube sampling, Sobolâ€™ sequences and Halton sequences. 
</div>
<div class="Indented">
<div class="center">
<img class="embedded" src="QMC.png" alt="figure QMC.png" style="max-width: 732px; max-height: 306px;"/>

</div>

</div>
<div class="Indented">
In this course we will use techniques based on <b>low-discrepancy sequences</b>. For them, the error is <span class="formula"><span class="scriptfont">O</span><span class="array"><span class="arrayrow"><span class="bracket align-left">â›</span></span><span class="arrayrow"><span class="bracket align-left">â</span></span></span><span class="fraction"><span class="ignored">(</span><span class="numerator">log(<i>N</i>)<sup><i>d</i></sup></span><span class="ignored">)/(</span><span class="denominator"><i>N</i></span><span class="ignored">)</span></span><span class="array"><span class="arrayrow"><span class="bracket align-right">â</span></span><span class="arrayrow"><span class="bracket align-right">â </span></span></span>,â€…</span> where <span class="formula"><i>d</i></span> is the dimension.
</div>
<div class="Indented">
One example of low-discrepancy sequences are the Halton Sequences. They consist in choosing a prime number <span class="formula"><i>p</i></span> and dividing the interval in <span class="formula"><i>p</i></span> subintervals, and then each interval in other <span class="formula"><i>p</i></span> subintervals, and so on until reaching the desired number of points.
</div>
<div class="Indented">
In chaospy, it is very easy to generate QMC samples. If for example for generating 1000 Halton sequence-based samples on an uniform distribution:
</div>
<div class="Indented">
<tt>distr = chaospy.Uniform()</tt>
</div>
<div class="Indented">
<tt>samples = distr.sample(size=1000, rule=â€™Hâ€™)</tt>
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-3">3</a>â€ƒBasic Interpolation and Quadrature
</h1>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.1">3.1</a>â€ƒInterpolation
</h2>
<div class="Unindented">
Interpolating consists in having some data points and estimating unknown values between those points. One way to do this is using polynomials, because they are analytically simple and computationally cheap.
</div>
<div class="Indented">
Given a continuous function, and a grid where we know the value of the function, there exists a <b>unique</b> polynomial of degree <span class="formula"><i>N</i></span> that satisfies the value of the function on those points. This polynomial can be expressed as a sum of <b>Lagrange cardinal polynomials</b>.
</div>
<div class="Indented">
For a certain grid there is a unique polynomial, but we have freedom in choosing the grid. For defining the error of the interpolation, we can relate the error of our interpolation taking grid <span class="formula"><i>G</i></span> with respect to the real function in terms of the error of an interpolation with the <i>best approximation polynomial</i> (with the same number of nodes).
</div>
<div class="Indented">
<div class="formula">
<i>Error</i><sub><i>G</i></sub>â€…â‰¤â€…(1â€…+â€…Î›<sub><i>N</i></sub>(<i>G</i>))<span class="symbol">(</span><i>Error</i><sub><span class="text">Best grid</span></sub><span class="symbol">)</span>
</div>

</div>
<div class="Indented">
<span class="formula">Î›</span> is the <b>Lebesgue constant</b> relative to the grid <span class="formula"><i>G</i></span>, and contains all the information about the effect of the grid choice.
</div>
<div class="Indented">
Lagrange interpolation on an uniform grid is not always a good idea, it can have strong variations near the limits of the interval (this is called the <b>Runge phenomenon</b>). Possible remedies for this is to use non-uniform grids (as Chebyscheff nodes) or different basis functions (maybe functions with local support, e.g. splines).
</div>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-3.2">3.2</a>â€ƒQuadrature
</h2>
<div class="Unindented">
The idea of Quadrature is to approximate the definite integral of a function based on function evaluations. Quadrature uses rules that integrate polynomials exactly.
</div>
<div class="Indented">
The general form of quadrature is a weighted sum of function values, however, as the function evaluation can be very computationally expensive, we need rules with small error of quadrature using few evaluations.
</div>
<div class="Indented">
Gaussian Quadrature uses not only the weights of the quadrature as degrees of freedom, but also the nodes on the grid. If we make a quadrature considering <span class="formula"><i>N</i>â€…+â€…1</span> points (quadrature of degree <span class="formula"><i>N</i></span>), this technique can integrate exactly polynomials of degree up to <span class="formula">2<i>N</i>â€…+â€…1.</span> Gaussian quadrature has the following form:
</div>
<div class="Indented">
<div class="formula">
<span class="limits"><span class="limit">âŒ </span><span class="limit">âŒ¡</span></span><i>f</i>(<i>x</i>)<i>w</i>(<i>x</i>)<span class="text">d</span><i>x</i>â€…=â€…<span class="limits"><sup class="limit"><i>N</i></sup><span class="limit">â²</span><span class="limit">â³</span><sub class="limit"><i>i</i>â€…=â€…0</sub></span><i>w</i><sub><i>i</i></sub><i>f</i>(<i>x</i><sub><i>i</i></sub>)â€…+â€…<i>Ïµ</i>
</div>

</div>
<div class="Indented">
Again, <span class="formula"><i>Ïµ</i>â€…=â€…0</span> for polynomials up to degree <span class="formula">2<i>N</i>â€…+â€…1.</span> 
</div>
<div class="Indented">
Note that we are integrating not only <span class="formula"><i>f</i></span>, but a product with <span class="formula"><i>w</i>.</span> This is a weight function, and this makes it is useful for UQ when we take <span class="formula"><i>w</i></span> as a probabilty distribution. This would be equivalent to taking the expected value of <span class="formula"><i>f</i>(<i>x</i>)</span> with respect to the probability distribution <span class="formula"><i>w</i>(<i>x</i>).</span> On the right side, <span class="formula"><i>w</i><sub><i>i</i></sub></span> corresponds to the weights given to each point evaluation, and <span class="formula"><i>x</i><sub><i>i</i></sub></span> correspond to the nodes. 
</div>
<div class="Paragraph">
<a class="toc" name="toc-Paragraph-2"></a>Getting the nodes
</div>
<div class="Unindented">
We can find the nodes if we find a family of polinomials <span class="formula"><i>p</i><sub><i>i</i></sub>(<i>x</i>)</span> that is orthogonal with respect to <span class="formula"><i>w</i>(<i>x</i>)</span> (i.e. <span class="formula"><span class="limits"><span class="limit">âˆ«</span></span><i>p</i><sub><i>i</i></sub>(<i>x</i>)<i>p</i><sub><i>j</i></sub>(<i>x</i>)<i>w</i>(<i>x</i>)<i>dx</i>â€…=â€…<i>Î´</i><sub><i>ij</i></sub>).</span> Then the nodes are simply the roots of the polynomial <span class="formula"><i>p</i><sub><i>N</i>â€…+â€…1</sub>.</span> For <span class="formula"><i>w</i></span> constant (as in the uniform probability distribution) our orthogonal family is the <b>Legendre polynomials</b>. For <span class="formula"><i>w</i></span> gaussian (as in the normal distribution) our family is the <b>Hermite polynomials</b>.
</div>
<div class="Paragraph">
<a class="toc" name="toc-Paragraph-3"></a>Getting the weights
</div>
<div class="Unindented">
The weights can be computed with the Lagrange cardinal polynomials evaluated at the nodes, integrated with respect to the weight function (at the end of the day we are integrating a <span class="formula">(2<i>N</i>â€…+â€…1)</span>-degree interpolation of <span class="formula"><i>f</i>(<i>x</i>)</span>).
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-4">4</a>â€ƒPolynomial Chaos
</h1>
<div class="Unindented">
Forward UQ consists on having a stochastic input that goes into a model <span class="formula"><i>f</i></span>, and a stochastic output which we want to characterize in the cheapest way possible. Montecarlo methods (and its improved versions) have slow convergence and need many samples. Another idea is to approximate our model <span class="formula"><i>f</i></span> with a series of polynomials:<div class="formula">
<i>f</i>(<i>t</i>,â€…<i>Ï‰</i>)â€…â‰ˆâ€…<span class="limits"><sup class="limit"><i>N</i>â€…âˆ’â€…1</sup><span class="limit">â²</span><span class="limit">â³</span><sub class="limit"><i>n</i>â€…=â€…0</sub></span><i>fÌ‚</i><sub><i>n</i></sub>(<i>t</i>)<i>Ï†</i><sub><i>n</i></sub>(<i>Ï‰</i>)
</div>

</div>
<div class="Indented">
where <span class="formula"><i>t</i></span> represent the independent variable(s) of our model, <span class="formula"><i>Ï‰</i></span> is the stochastic input variable (with distribution <span class="formula"><i>Ï</i>(<i>Ï‰</i>)</span>), <span class="formula"><i>fÌ‚</i><sub><i>n</i></sub>(<i>t</i>)</span> are the coefficients of the polynomials (note that are independent on the stochastic variable) and <span class="formula"><i>Ï†</i><sub><i>n</i></sub>(<i>Ï‰</i>)</span> are orthogonal polynomials of degree <span class="formula"><i>n</i></span> purely dependent on the stochastic variable. 
</div>
<div class="Indented">
In order to make this approximation we have to define the family of polynomials, compute the coefficients, choose the maximum order of the polynomials and finally characterize the output using this approximation.
</div>
<h2 class="Subsection-">
<a class="toc" name="toc-Subsection--1"></a>Choosing the type of polynomials
</h2>
<div class="Unindented">
The orthogonal polynomials <span class="formula"><i>Ï†</i><sub><i>n</i></sub>(<i>Ï‰</i>)</span> would be chosen according to the input distribution of the stochastic variable (<span class="formula"><i>Ï</i>(<i>Ï‰</i>)</span>). For example for a uniform distribution we would choose Legendre polynomials, for a normal distribution we would choose Hermite polynomials, and so on. Computation of other families of polynomials can be made with the Stieltjesâ€™ <b>three-term recursion relation</b>, which is satisfied by all orthogonal polynomials, and can be gotten with a numerically stable method, or we could use other schemes as a Gram-Schmidt algorithm.
</div>
<h2 class="Subsection-">
<a class="toc" name="toc-Subsection--2"></a>Computing the coefficients
</h2>
<div class="Unindented">
As our polynomials represent an orthonormal basis, we could compute our coefficients with a simple inner product with respect to <span class="formula"><i>Ï</i>(<i>Ï‰</i>)</span>:
</div>
<div class="Indented">
<div class="formula">
<i>fÌ‚</i><sub><i>n</i></sub>(<i>t</i>)â€…=â€…<span class="symbol">âŸ¨</span><i>f</i>(<i>t</i>,â€…<i>Ï‰</i>),â€…<i>Ï†</i><sub><i>n</i></sub>(<i>Ï‰</i>)<span class="symbol">âŸ©</span><sub><i>Ï</i></sub>â€…=â€…<span class="limits"><span class="limit">âŒ </span><span class="limit">âŒ¡</span></span><i>f</i>(<i>t</i>,â€…<i>Ï‰</i>)<i>Ï†</i><sub><i>n</i></sub>(<i>Ï‰</i>)<i>Ï</i>(<i>Ï‰</i>)<i>d</i><i>Ï‰</i>
</div>

</div>
<div class="Indented">
This way of getting the coefficients is called the <b>pseudo-spectral approach</b>. 
</div>
<div class="Indented">
That inner product is computed through an integral, and as <span class="formula"><i>f</i></span> can be expensive or even a black box, we rather use quadrature to solve it. Gaussian quadrature is specially adequate for this. We just need to get the nodes and weights (that depend solely on the probability distribution <span class="formula"><i>Ï</i></span>) and then we would only have to evaluate <span class="formula"><i>f</i></span> once at every node. This would yield:
</div>
<div class="Indented">
<div class="formula">
<i>fÌ‚</i><sub><i>n</i></sub>â€…=â€…<span class="limits"><sup class="limit"><i>K</i>â€…âˆ’â€…1</sup><span class="limit">â²</span><span class="limit">â³</span><sub class="limit"><i>k</i>â€…=â€…0</sub></span><i>w</i><sub><i>k</i></sub><i>f</i>(<i>t</i>,â€…<i>Ï‰</i><sub><i>k</i></sub>)<i>Ï†</i><sub><i>n</i></sub>(<i>Ï‰</i><sub><i>k</i></sub>)
</div>

</div>
<div class="Indented">
Note that the integral is with respect to <span class="formula"><i>Ï‰</i>,â€…</span> and thus the grid <span class="formula"><i>Ï‰</i><sub><i>k</i></sub></span> that we get as the roots of the polynomials, represent values of our stochastic variable <span class="formula"><i>Ï‰</i>.</span>
</div>
<h2 class="Subsection-">
<a class="toc" name="toc-Subsection--3"></a>Choosing maximum order of polynomials and quadrature
</h2>
<div class="Unindented">
Consider that the number of nodes to evaluate the integral (order of the quadrature) is completely independent of the number of terms used to represent our model (order of the interpolation):
</div>
<ul>
<li>
Using <span class="formula"><i>K</i></span> nodes to evaluate the quadrature would be as integrating exactly a polynomial of degree up to <span class="formula">2<i>K</i>â€…âˆ’â€…1</span> interpolating <span class="formula"><i>f</i>(<i>t</i>,â€…<i>Ï‰</i>)<i>Ï†</i><sub><i>n</i></sub>(<i>Ï‰</i>)</span> with respect to <span class="formula"><i>Ï‰</i>.</span> 
</li>
<li>
Independent of that, we have the polynomial of degree <span class="formula"><i>N</i>â€…âˆ’â€…1</span> that interpolates <span class="formula"><i>f</i>(<i>t</i>,â€…<i>Ï‰</i>)</span> with respect to <span class="formula"><i>Ï‰</i>.</span>
</li>

</ul>
<div class="Unindented">
It may be very expensive to evaluate <span class="formula"><i>f</i>(<i>t</i>,â€…<i>Ï‰</i><sub><i>k</i></sub>)</span>, but once these values are known, with them we can compute <span class="formula"><i>fÌ‚</i><sub><i>n</i></sub>,â€…</span> and with them we can evaluate our interpolation of <span class="formula"><i>f</i>(<i>t</i>,â€…<i>Ï‰</i>)</span> with low computational effort. Thus, our <span class="formula"><i>K</i></span> determines the computational effort. On the other side, generally <span class="formula"><i>f<sub>n</sub>Ì‚</i>(<i>t</i>)</span> decay exponentially with respect to <span class="formula"><i>n</i>,â€…</span> so few coefficients (low <span class="formula"><i>N</i></span>) are sufficient. As a rule of thumb we can use <span class="formula"><i>N</i>â€…â‰ˆâ€…<i>K</i>â€…â„â€…2.</span>
</div>
<h2 class="Subsection-">
<a class="toc" name="toc-Subsection--4"></a>Statistical properties of the approximation
</h2>
<div class="Unindented">
Once we have \strikeout off\xout off\uuline off\uwave off<span class="formula"><i>fÌ‚</i><sub><i>n</i></sub>(<i>t</i>)</span>, we can evaluate statistical moments of our resulting function <span class="formula"><i>f</i>(<i>t</i>,â€…<i>Ï‰</i>)â€…â‰ˆâ€…<span class="limits"><span class="limit">âˆ‘</span></span><span class="scripts"><sup class="script"><i>N</i>â€…âˆ’â€…1</sup><sub class="script"><i>n</i>â€…=â€…0</sub></span><i>fÌ‚</i><sub><i>n</i></sub>(<i>t</i>)<i>Ï†</i><sub><i>n</i></sub>(<i>Ï‰</i>)</span> pretty easily.
</div>
<ul>
<li>
<b>Expectation value:</b> <span class="formula">ğ”¼[<i>f</i>(<i>t</i>,â€…<i>Ï‰</i>)]â€…=â€…<i>fÌ‚</i><sub>0</sub>(<i>t</i>)</span> (just like in fourier series)
</li>
<li>
<b>Variance:</b> <span class="formula"><span class="text">Var</span>[<i>f</i>(<i>t</i>,â€…<i>Ï‰</i>)]â€…=â€…<span class="limits"><span class="limit">âˆ‘</span></span><span class="scripts"><sup class="script"><i>N</i>â€…âˆ’â€…1</sup><sub class="script"><i>n</i>â€…=â€…1</sub></span><i>fÌ‚</i><span class="scripts"><sup class="script">2</sup><sub class="script"><i>n</i></sub></span>(<i>t</i>)</span> (all the mixed terms vanish because of the orthogonality of our polynomials)
</li>

</ul>
<h2 class="Subsection">
<a class="toc" name="toc-Subsection-4.1">4.1</a>â€ƒMultivariate Polynomial Chaos Expansion
</h2>
<div class="Unindented">
This approach can be generalized for <span class="formula"><i>d</i></span> dimensions. Now instead of <span class="formula"><i>n</i></span> we have a vector <span class="formula"><b>n</b>â€…=â€…(<i>n</i><sub>1</sub>,â€…...,â€…<i>n</i><sub><i>d</i></sub>)â€…âˆˆâ€…â„•<sup><i>d</i></sup>,â€…</span> and our polynomials are product of one-dimensional polynomials (orthogonal with respect to the combination of all their indices). Generally for this approach one chooses a given <span class="formula"><i>N</i></span> as a global order, and then we have a finite number of combinations of <span class="formula"><span class="symbol">(</span><i>n</i><sub>1</sub>,â€…...,â€…<i>n</i><sub><i>d</i></sub><span class="symbol">)</span>,â€…</span>such that \strikeout off\xout off\uuline off\uwave off<span class="formula"><i>n</i><sub>1</sub>â€…+â€…...â€…+â€…<i>n</i><sub><i>d</i></sub>â€…â‰¤â€…<i>N</i>.</span> This number of combinations is notated by <span class="formula"><i>P</i>â‰”<span class="array"><span class="arrayrow"><span class="bracket align-left">â›</span></span><span class="arrayrow"><span class="bracket align-left">âœ</span></span><span class="arrayrow"><span class="bracket align-left">â</span></span></span><span class="array"><span class="arrayrow">
<span class="arraycell align-c">
<i>d</i>â€…+â€…<i>N</i>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-c">
â€…
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-c">
<i>d</i>
</span>

</span>
</span><span class="array"><span class="arrayrow"><span class="bracket align-right">â</span></span><span class="arrayrow"><span class="bracket align-right">âŸ</span></span><span class="arrayrow"><span class="bracket align-right">â </span></span></span></span>. The computational cost, which is <span class="formula"><i>K</i></span> is only indirectly related to <span class="formula"><i>P</i>.</span>
</div>
<h1 class="Section">
<a class="toc" name="toc-Section-5">5</a>â€ƒSparse Grids
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-6">6</a>â€ƒSensitivity Analysis
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-7">7</a>â€ƒRandom Fields
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-8">8</a>â€ƒSoftware
</h1>
<h1 class="Section">
<a class="toc" name="toc-Section-9">9</a>â€ƒBayesian Inverse Problems
</h1>

</div>
</body>
</html>
